---
- name: Get Routers in this namespace
  kubernetes.core.k8s_info:
    api_version: routernetes.net/v1alpha1
    kind: Router
    namespace: "{{ ansible_operator_meta.namespace }}"
    field_selectors:
      - metadata.name!={{ ansible_operator_meta.name }}
  register: this_namespace_routers

- name: Get Routers in other namespaces
  kubernetes.core.k8s_info:
    api_version: routernetes.net/v1alpha1
    kind: Router
    field_selectors:
      - metadata.namespace!={{ ansible_operator_meta.namespace }}
  register: other_namespace_routers

- name: Combine lists
  ansible.builtin.set_fact:
    routers: "{{ this_namespace_routers.resources + other_namespace_routers.resources }}"

- name: Get number of Routers
  ansible.builtin.set_fact:
    router_number: "{{ routers | length }}"

- name: Fail if another Router exists
  ansible.builtin.fail:
    msg: The system may only have 1 Router at a time.
  when: router_number|int > 0

- name: Copy configured DNS listen interface
  ansible.builtin.set_fact:
    dns_listen_interface: "{{ dns.listen_interface }}"
  when: dns.listen_interface is defined

- name: Set default DNS listen interface
  ansible.builtin.set_fact:
    dns_listen_interface: "{{ item.name }}"
  with_items: "{{ interfaces }}"
  when: dns_listen_interface is not defined and (item.zone is not defined or (item.zone is defined and item.zone == "inside"))

- name: Get node info
  kubernetes.core.k8s_info:
    api_version: v1
    kind: Node
  register: node_info

- name: Set zincati default
  ansible.builtin.set_fact:
    has_zincati: false

- name: Check for zincati
  ansible.builtin.set_fact:
    has_zincati: true
  when: node_info["resources"][0]["status"]["nodeInfo"]["osImage"].startswith("Fedora CoreOS")

- name: dnsmasq-config
  kubernetes.core.k8s:
    template:
      path: dnsmasq-config.yaml.j2
      trim_blocks: false
    apply: true
    server_side_apply:
      field_manager: ansible
      force_conflicts: true
  notify:
    - restart daemonset

- name: firewalld-config
  kubernetes.core.k8s:
    template:
      path: firewalld-config.yaml.j2
      trim_blocks: false
    apply: true
    server_side_apply:
      field_manager: ansible
      force_conflicts: true
  notify:
    - restart daemonset

- name: zincati-config
  kubernetes.core.k8s:
    template:
      path: zincati-config.yaml.j2
      trim_blocks: false
    apply: true
    server_side_apply:
      field_manager: ansible
      force_conflicts: true
  notify:
    - restart daemonset
  when: has_zincati

- name: nm-config
  kubernetes.core.k8s:
    template:
      path: nm-config.yaml.j2
      trim_blocks: false
    apply: true
    server_side_apply:
      field_manager: ansible
      force_conflicts: true
  notify:
    - restart daemonset

- name: dhcp-pvc
  kubernetes.core.k8s:
    template:
      path: dhcp-pvc.yaml.j2
      trim_blocks: false
    apply: true
    server_side_apply:
      field_manager: ansible
      force_conflicts: true

- name: service-account
  kubernetes.core.k8s:
    template:
      path: service-account.yaml.j2
      trim_blocks: false
    apply: true
    server_side_apply:
      field_manager: ansible
      force_conflicts: true

- name: Check for OpenShift SCC
  kubernetes.core.k8s_info:
    api_version: rbac.authorization.k8s.io/v1
    kind: ClusterRole
    name: system:openshift:scc:privileged
  register: openshift_scc

- name: Convert to length
  ansible.builtin.set_fact:
    scc_number: "{{ openshift_scc.resources | length }}"

- name: cluster-role-binding
  kubernetes.core.k8s:
    template:
      path: cluster-role-binding.yaml.j2
      trim_blocks: false
    apply: true
    server_side_apply:
      field_manager: ansible
      force_conflicts: true
  when: scc_number|int > 0

- name: daemonset
  kubernetes.core.k8s:
    template:
      path: daemonset.yaml.j2
      trim_blocks: false
    apply: true
    server_side_apply:
      field_manager: ansible
      force_conflicts: true
  register: daemonset_status
